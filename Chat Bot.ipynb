{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('train_qa.txt', 'rb') as f:\n",
    "    train_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open ('test_qa.txt', 'rb') as f:\n",
    "    test_data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mary moved to the bathroom . Sandra journeyed to the bedroom .'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\" \".join(train_data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Is Sandra in the hallway ?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " \" \".join(train_data[0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_data = test_data + train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = set()\n",
    "\n",
    "for story,question,answer in all_data:\n",
    "    vocab = vocab.union(set(story))\n",
    "    vocab = vocab.union(set(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab.add('no')\n",
    "vocab.add('yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder\n",
    "vocab_len = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longest Story\n",
    "all_story_lens = [len(data[0]) for data in all_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_story_len = max(all_story_lens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_question_len = max([len(data[1]) for data in all_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_question_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(filters=[])\n",
    "tokenizer.fit_on_texts(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bathroom': 1,\n",
       " 'dropped': 2,\n",
       " 'yes': 3,\n",
       " 'picked': 4,\n",
       " 'mary': 5,\n",
       " 'travelled': 6,\n",
       " 'milk': 7,\n",
       " 'football': 8,\n",
       " 'grabbed': 9,\n",
       " 'back': 10,\n",
       " 'daniel': 11,\n",
       " 'in': 12,\n",
       " 'left': 13,\n",
       " 'took': 14,\n",
       " 'up': 15,\n",
       " 'to': 16,\n",
       " 'went': 17,\n",
       " 'john': 18,\n",
       " 'hallway': 19,\n",
       " 'office': 20,\n",
       " 'is': 21,\n",
       " 'no': 22,\n",
       " 'got': 23,\n",
       " 'apple': 24,\n",
       " '.': 25,\n",
       " 'garden': 26,\n",
       " 'journeyed': 27,\n",
       " 'put': 28,\n",
       " 'the': 29,\n",
       " 'bedroom': 30,\n",
       " 'down': 31,\n",
       " 'discarded': 32,\n",
       " 'moved': 33,\n",
       " 'there': 34,\n",
       " '?': 35,\n",
       " 'sandra': 36,\n",
       " 'kitchen': 37}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_text = []\n",
    "train_question_text = []\n",
    "train_answers = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "for story,question,answer in train_data:\n",
    "    train_story_text.append(story)\n",
    "    train_question_text.append(question)\n",
    "    train_answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_story_seq = tokenizer.texts_to_sequences(train_story_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the story, question, and answer\n",
    "def vectorize_stories(data,word_index=tokenizer.word_index,max_story_len=max_story_len,max_question_len=max_question_len):\n",
    "    # Stories = X\n",
    "    X = []\n",
    "    \n",
    "    # Questions Xq\n",
    "    Xq = []\n",
    "    \n",
    "    # Correct Answer (y/n)\n",
    "    Y = []\n",
    "    \n",
    "    for story,query,answer in data:\n",
    "        x = [word_index[word.lower()] for word in story]\n",
    "        xq = [word_index[word.lower()] for word in query]\n",
    "        \n",
    "        y = np.zeros(len(word_index)+1)\n",
    "        \n",
    "        y[word_index[answer]] = 1\n",
    "        \n",
    "        X.append(x)\n",
    "        Xq.append(xq)\n",
    "        Y.append(y)\n",
    "        \n",
    "    return (pad_sequences(X,maxlen=max_story_len),pad_sequences(Xq,maxlen=max_question_len),np.array(Y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_train, queries_train, answers_train = vectorize_stories(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_test, queries_test, answers_test = vectorize_stories(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  0,  0, ..., 29, 30, 25],\n",
       "       [ 0,  0,  0, ..., 29, 26, 25],\n",
       "       [ 0,  0,  0, ..., 29, 26, 25],\n",
       "       ...,\n",
       "       [ 0,  0,  0, ..., 29, 24, 25],\n",
       "       [ 0,  0,  0, ..., 29, 26, 25],\n",
       "       [ 0,  0,  0, ..., 24, 34, 25]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.word_index['no']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0.,   0.,   0., 497.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "       503.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,   0.,\n",
       "         0.,   0.,   0.,   0.,   0.])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(answers_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential,Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.layers import Input,Activation,Dense,Permute,Dropout,add,dot,concatenate,LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PlaceHolder shape = (max_story_len,batch_size)\n",
    "input_sequence = Input((max_story_len,))\n",
    "question = Input((max_question_len,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocab_len\n",
    "vocab_size = len(vocab) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Encoder M\n",
    "input_encoder_m = Sequential()\n",
    "input_encoder_m.add(Embedding(input_dim=vocab_size,output_dim=64))\n",
    "input_encoder_m.add(Dropout(0.5))\n",
    "\n",
    "# OUPUT = (samples,story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input Encoder C\n",
    "input_encoder_c = Sequential()\n",
    "input_encoder_c.add(Embedding(input_dim=vocab_size,output_dim=max_question_len))\n",
    "input_encoder_c.add(Dropout(0.5))\n",
    "\n",
    "# OUTPUT = (samples,story_maxlen, embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_encoder = Sequential()\n",
    "question_encoder.add(Embedding(input_dim=vocab_size,output_dim=64,input_length=max_question_len))\n",
    "question_encoder.add(Dropout(0.5))\n",
    "\n",
    "# OUTPUT = (samples, query_maxlen,embedding_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ENCODED <----- ENCODER(INPUT)\n",
    "input_encoded_m = input_encoder_m(input_sequence)\n",
    "input_encoded_c = input_encoder_c(input_sequence)\n",
    "question_encoded = question_encoder(question)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "match = dot([input_encoded_m,question_encoded], axes=(2,2))\n",
    "match = Activation('softmax')(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = add([match,input_encoded_c])\n",
    "response= Permute((2, 1))(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = concatenate([response,question_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 6, 220) dtype=float32>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = LSTM(32)(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Dropout(0.5)(answer)\n",
    "answer = Dense(vocab_size)(answer) # y/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = Activation('softmax')(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input_sequence,question],answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 156)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 6)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequential_8 (Sequential)       multiple             2432        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "sequential_11 (Sequential)      (None, 6, 64)        2432        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dot_1 (Dot)                     (None, 156, 6)       0           sequential_8[1][0]               \n",
      "                                                                 sequential_11[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 156, 6)       0           dot_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "sequential_9 (Sequential)       multiple             228         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 156, 6)       0           activation_1[0][0]               \n",
      "                                                                 sequential_9[1][0]               \n",
      "__________________________________________________________________________________________________\n",
      "permute_1 (Permute)             (None, 6, 156)       0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 6, 220)       0           permute_1[0][0]                  \n",
      "                                                                 sequential_11[1][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 32)           32384       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 32)           0           lstm_1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 38)           1254        dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 38)           0           dense_1[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 38,730\n",
      "Trainable params: 38,730\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Andy\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From C:\\Users\\Andy\\Anaconda3\\envs\\nlp_course\\lib\\site-packages\\tensorflow\\python\\ops\\math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "Train on 10000 samples, validate on 1000 samples\n",
      "Epoch 1/100\n",
      "10000/10000 [==============================] - 7s 706us/step - loss: 0.9291 - val_loss: 0.6941\n",
      "Epoch 2/100\n",
      "10000/10000 [==============================] - 5s 542us/step - loss: 0.7028 - val_loss: 0.6977\n",
      "Epoch 3/100\n",
      "10000/10000 [==============================] - 7s 715us/step - loss: 0.6959 - val_loss: 0.6939\n",
      "Epoch 4/100\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 0.6955 - val_loss: 0.6932\n",
      "Epoch 5/100\n",
      "10000/10000 [==============================] - 5s 529us/step - loss: 0.6946 - val_loss: 0.6932\n",
      "Epoch 6/100\n",
      "10000/10000 [==============================] - 5s 539us/step - loss: 0.6952 - val_loss: 0.6948\n",
      "Epoch 7/100\n",
      "10000/10000 [==============================] - 5s 537us/step - loss: 0.6946 - val_loss: 0.6932\n",
      "Epoch 8/100\n",
      "10000/10000 [==============================] - 6s 566us/step - loss: 0.6942 - val_loss: 0.6932\n",
      "Epoch 9/100\n",
      "10000/10000 [==============================] - 5s 522us/step - loss: 0.6942 - val_loss: 0.6934\n",
      "Epoch 10/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.6941 - val_loss: 0.6958\n",
      "Epoch 11/100\n",
      "10000/10000 [==============================] - 5s 521us/step - loss: 0.6942 - val_loss: 0.6934: 0.\n",
      "Epoch 12/100\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 0.6943 - val_loss: 0.6934\n",
      "Epoch 13/100\n",
      "10000/10000 [==============================] - 5s 526us/step - loss: 0.6943 - val_loss: 0.6936\n",
      "Epoch 14/100\n",
      "10000/10000 [==============================] - 5s 544us/step - loss: 0.6941 - val_loss: 0.6935\n",
      "Epoch 15/100\n",
      "10000/10000 [==============================] - 5s 517us/step - loss: 0.6935 - val_loss: 0.6941: 0\n",
      "Epoch 16/100\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 0.6939 - val_loss: 0.6953\n",
      "Epoch 17/100\n",
      "10000/10000 [==============================] - 5s 535us/step - loss: 0.6940 - val_loss: 0.6941\n",
      "Epoch 18/100\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.6934 - val_loss: 0.6943\n",
      "Epoch 19/100\n",
      "10000/10000 [==============================] - 5s 547us/step - loss: 0.6925 - val_loss: 0.6959\n",
      "Epoch 20/100\n",
      "10000/10000 [==============================] - 5s 536us/step - loss: 0.6915 - val_loss: 0.6944\n",
      "Epoch 21/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.6894 - val_loss: 0.6918\n",
      "Epoch 22/100\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.6844 - val_loss: 0.6821\n",
      "Epoch 23/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.6681 - val_loss: 0.6545\n",
      "Epoch 24/100\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.6481 - val_loss: 0.6181\n",
      "Epoch 25/100\n",
      "10000/10000 [==============================] - 6s 557us/step - loss: 0.6044 - val_loss: 0.5457\n",
      "Epoch 26/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.5598 - val_loss: 0.5100\n",
      "Epoch 27/100\n",
      "10000/10000 [==============================] - 5s 522us/step - loss: 0.5234 - val_loss: 0.4724\n",
      "Epoch 28/100\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.4887 - val_loss: 0.4461\n",
      "Epoch 29/100\n",
      "10000/10000 [==============================] - 5s 526us/step - loss: 0.4734 - val_loss: 0.4372\n",
      "Epoch 30/100\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.4586 - val_loss: 0.4222\n",
      "Epoch 31/100\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 0.4458 - val_loss: 0.4355\n",
      "Epoch 32/100\n",
      "10000/10000 [==============================] - 5s 522us/step - loss: 0.4339 - val_loss: 0.4094\n",
      "Epoch 33/100\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.4204 - val_loss: 0.4007\n",
      "Epoch 34/100\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.3974 - val_loss: 0.4233\n",
      "Epoch 35/100\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.3858 - val_loss: 0.3767\n",
      "Epoch 36/100\n",
      "10000/10000 [==============================] - 6s 571us/step - loss: 0.3763 - val_loss: 0.3651\n",
      "Epoch 37/100\n",
      "10000/10000 [==============================] - 6s 610us/step - loss: 0.3707 - val_loss: 0.3627ETA: 0s - loss: \n",
      "Epoch 38/100\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.3685 - val_loss: 0.3627\n",
      "Epoch 39/100\n",
      "10000/10000 [==============================] - 5s 537us/step - loss: 0.3557 - val_loss: 0.3607\n",
      "Epoch 40/100\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.3505 - val_loss: 0.3534\n",
      "Epoch 41/100\n",
      "10000/10000 [==============================] - 5s 526us/step - loss: 0.3461 - val_loss: 0.3467\n",
      "Epoch 42/100\n",
      "10000/10000 [==============================] - 6s 561us/step - loss: 0.3460 - val_loss: 0.3550\n",
      "Epoch 43/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.3446 - val_loss: 0.3493\n",
      "Epoch 44/100\n",
      "10000/10000 [==============================] - 5s 521us/step - loss: 0.3405 - val_loss: 0.3543\n",
      "Epoch 45/100\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.3321 - val_loss: 0.3524\n",
      "Epoch 46/100\n",
      "10000/10000 [==============================] - 5s 533us/step - loss: 0.3279 - val_loss: 0.3380\n",
      "Epoch 47/100\n",
      "10000/10000 [==============================] - 6s 554us/step - loss: 0.3366 - val_loss: 0.3577\n",
      "Epoch 48/100\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.3285 - val_loss: 0.3346\n",
      "Epoch 49/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.3301 - val_loss: 0.3426ss\n",
      "Epoch 50/100\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.3268 - val_loss: 0.3432\n",
      "Epoch 51/100\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.3221 - val_loss: 0.3366\n",
      "Epoch 52/100\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.3226 - val_loss: 0.3529\n",
      "Epoch 53/100\n",
      "10000/10000 [==============================] - ETA: 0s - loss: 0.3227- ETA: 0s - loss: 0.3 - 6s 554us/step - loss: 0.3228 - val_loss: 0.3420\n",
      "Epoch 54/100\n",
      "10000/10000 [==============================] - 5s 527us/step - loss: 0.3208 - val_loss: 0.34053s - - ETA: 2\n",
      "Epoch 55/100\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 0.3148 - val_loss: 0.3420\n",
      "Epoch 56/100\n",
      "10000/10000 [==============================] - 6s 560us/step - loss: 0.3171 - val_loss: 0.3384\n",
      "Epoch 57/100\n",
      "10000/10000 [==============================] - 5s 541us/step - loss: 0.3154 - val_loss: 0.3332\n",
      "Epoch 58/100\n",
      "10000/10000 [==============================] - 6s 557us/step - loss: 0.3178 - val_loss: 0.3331\n",
      "Epoch 59/100\n",
      "10000/10000 [==============================] - 6s 600us/step - loss: 0.3188 - val_loss: 0.3467\n",
      "Epoch 60/100\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 0.3106 - val_loss: 0.3523\n",
      "Epoch 61/100\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.3161 - val_loss: 0.3474\n",
      "Epoch 62/100\n",
      "10000/10000 [==============================] - 5s 546us/step - loss: 0.3126 - val_loss: 0.3418\n",
      "Epoch 63/100\n",
      "10000/10000 [==============================] - 5s 546us/step - loss: 0.3139 - val_loss: 0.3516\n",
      "Epoch 64/100\n",
      "10000/10000 [==============================] - 6s 556us/step - loss: 0.3003 - val_loss: 0.3589\n",
      "Epoch 65/100\n",
      "10000/10000 [==============================] - 5s 526us/step - loss: 0.3088 - val_loss: 0.3411\n",
      "Epoch 66/100\n",
      "10000/10000 [==============================] - 5s 528us/step - loss: 0.3108 - val_loss: 0.3426\n",
      "Epoch 67/100\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.3078 - val_loss: 0.3477\n",
      "Epoch 68/100\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 0.3067 - val_loss: 0.3424\n",
      "Epoch 69/100\n",
      "10000/10000 [==============================] - 5s 538us/step - loss: 0.3013 - val_loss: 0.3520\n",
      "Epoch 70/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 5s 545us/step - loss: 0.3085 - val_loss: 0.3447\n",
      "Epoch 71/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.3084 - val_loss: 0.3477\n",
      "Epoch 72/100\n",
      "10000/10000 [==============================] - 5s 494us/step - loss: 0.2981 - val_loss: 0.3462\n",
      "Epoch 73/100\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 0.3022 - val_loss: 0.3420\n",
      "Epoch 74/100\n",
      "10000/10000 [==============================] - 5s 511us/step - loss: 0.3011 - val_loss: 0.3503\n",
      "Epoch 75/100\n",
      "10000/10000 [==============================] - 5s 522us/step - loss: 0.3020 - val_loss: 0.3479\n",
      "Epoch 76/100\n",
      "10000/10000 [==============================] - 5s 538us/step - loss: 0.3003 - val_loss: 0.34160s - lo\n",
      "Epoch 77/100\n",
      "10000/10000 [==============================] - 5s 520us/step - loss: 0.2955 - val_loss: 0.3568\n",
      "Epoch 78/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.3019 - val_loss: 0.3625\n",
      "Epoch 79/100\n",
      "10000/10000 [==============================] - 5s 519us/step - loss: 0.2993 - val_loss: 0.3534\n",
      "Epoch 80/100\n",
      "10000/10000 [==============================] - 5s 531us/step - loss: 0.2941 - val_loss: 0.3498\n",
      "Epoch 81/100\n",
      "10000/10000 [==============================] - 6s 555us/step - loss: 0.2990 - val_loss: 0.3632\n",
      "Epoch 82/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.2980 - val_loss: 0.3587: 0.\n",
      "Epoch 83/100\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 0.2914 - val_loss: 0.3515\n",
      "Epoch 84/100\n",
      "10000/10000 [==============================] - 5s 528us/step - loss: 0.2961 - val_loss: 0.3539\n",
      "Epoch 85/100\n",
      "10000/10000 [==============================] - 5s 525us/step - loss: 0.2888 - val_loss: 0.3568\n",
      "Epoch 86/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.2999 - val_loss: 0.3590\n",
      "Epoch 87/100\n",
      "10000/10000 [==============================] - 5s 538us/step - loss: 0.2965 - val_loss: 0.3549\n",
      "Epoch 88/100\n",
      "10000/10000 [==============================] - 5s 532us/step - loss: 0.2928 - val_loss: 0.3558\n",
      "Epoch 89/100\n",
      "10000/10000 [==============================] - 5s 519us/step - loss: 0.2923 - val_loss: 0.3579\n",
      "Epoch 90/100\n",
      "10000/10000 [==============================] - 5s 521us/step - loss: 0.2944 - val_loss: 0.3607\n",
      "Epoch 91/100\n",
      "10000/10000 [==============================] - 5s 503us/step - loss: 0.2930 - val_loss: 0.3608\n",
      "Epoch 92/100\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.2860 - val_loss: 0.3797\n",
      "Epoch 93/100\n",
      "10000/10000 [==============================] - 5s 544us/step - loss: 0.2865 - val_loss: 0.3591\n",
      "Epoch 94/100\n",
      "10000/10000 [==============================] - 5s 523us/step - loss: 0.2848 - val_loss: 0.3752\n",
      "Epoch 95/100\n",
      "10000/10000 [==============================] - 5s 524us/step - loss: 0.2877 - val_loss: 0.3582\n",
      "Epoch 96/100\n",
      "10000/10000 [==============================] - 5s 518us/step - loss: 0.2851 - val_loss: 0.3748\n",
      "Epoch 97/100\n",
      "10000/10000 [==============================] - 5s 530us/step - loss: 0.2873 - val_loss: 0.3696\n",
      "Epoch 98/100\n",
      "10000/10000 [==============================] - 5s 540us/step - loss: 0.2881 - val_loss: 0.3527\n",
      "Epoch 99/100\n",
      "10000/10000 [==============================] - 6s 601us/step - loss: 0.2907 - val_loss: 0.3583\n",
      "Epoch 100/100\n",
      "10000/10000 [==============================] - 6s 633us/step - loss: 0.2806 - val_loss: 0.3771\n"
     ]
    }
   ],
   "source": [
    "history = model.fit([inputs_train,queries_train],answers_train,batch_size=32,epochs=100,validation_data=([inputs_test,queries_test],answers_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('myModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('myModel.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([inputs_test,queries_test]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2.7068219e-14, 2.3831916e-14, 2.2445306e-14, 1.7412609e-04,\n",
       "       2.3667707e-14, 2.3383851e-14, 2.5227948e-14, 2.1530917e-14,\n",
       "       2.2157000e-14, 2.1932138e-14, 2.3418487e-14, 2.0264421e-14,\n",
       "       2.2742133e-14, 2.3487063e-14, 2.2494036e-14, 2.6704738e-14,\n",
       "       2.7183388e-14, 2.5401964e-14, 2.1510270e-14, 2.5087066e-14,\n",
       "       2.3379659e-14, 2.4692098e-14, 9.9982589e-01, 2.2613669e-14,\n",
       "       2.3370029e-14, 2.0976386e-14, 2.4991406e-14, 2.4494897e-14,\n",
       "       2.2416812e-14, 2.3827325e-14, 2.1260480e-14, 2.3496562e-14,\n",
       "       2.2816953e-14, 2.3988890e-14, 2.2747253e-14, 2.1947369e-14,\n",
       "       2.5132997e-14, 2.0158639e-14], dtype=float32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'John', 'in', 'the', 'kitchen', '?']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[0][2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'no'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9998259"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_results[0][val_max]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'.',\n",
       " '?',\n",
       " 'Daniel',\n",
       " 'Is',\n",
       " 'John',\n",
       " 'Mary',\n",
       " 'Sandra',\n",
       " 'apple',\n",
       " 'back',\n",
       " 'bathroom',\n",
       " 'bedroom',\n",
       " 'discarded',\n",
       " 'down',\n",
       " 'dropped',\n",
       " 'football',\n",
       " 'garden',\n",
       " 'got',\n",
       " 'grabbed',\n",
       " 'hallway',\n",
       " 'in',\n",
       " 'journeyed',\n",
       " 'kitchen',\n",
       " 'left',\n",
       " 'milk',\n",
       " 'moved',\n",
       " 'no',\n",
       " 'office',\n",
       " 'picked',\n",
       " 'put',\n",
       " 'the',\n",
       " 'there',\n",
       " 'to',\n",
       " 'took',\n",
       " 'travelled',\n",
       " 'up',\n",
       " 'went',\n",
       " 'yes'}"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run your Own Stories\n",
    "my_story = \"John left the kitchen . Sandra dropped the football in the garden . \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['John',\n",
       " 'left',\n",
       " 'the',\n",
       " 'kitchen',\n",
       " '.',\n",
       " 'Sandra',\n",
       " 'dropped',\n",
       " 'the',\n",
       " 'football',\n",
       " 'in',\n",
       " 'the',\n",
       " 'garden',\n",
       " '.']"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_story.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_question = \"Is the football in the garden ?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Is', 'the', 'football', 'in', 'the', 'garden', '?']"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_question.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydata = [(my_story.split(),my_question.split(), 'yes')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_story, my_ques, my_ans = vectorize_stories(mydata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_results = model.predict(([my_story,my_ques]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(pred_results[0])\n",
    "for key,val in tokenizer.word_index.items():\n",
    "    if val == val_max:\n",
    "        k = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'yes'"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
